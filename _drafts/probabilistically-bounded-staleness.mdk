---
title: Probabilistically Bounded Staleness
layout: post
description: |
  The semantics of eventual consistency don't guarantee anything about the staleness of accessed data. However, users of these datastores typically observe "good enough" consistency that it's worth the improved latency and availability they provide. Peter Bailis and his colleagues at Berkeley set out to quantify the staleness in actual deployed systems and developed models that can predict the probability that a value will be stale.
---

Peter Bailis came and gave a talk at UW a few months ago while I was out of town. Since then, every time I tell someone about my current research project, they say something along the lines of, "Oh, did you get a chance to talk about this with Peter Bailis when he visited? His work sounds totally relevant to what you're proposing." Well, I finally got around to reading some of these papers, and it is in fact very relevant and really fantastic work which I will definitely want to lean on. I'll do my best to briefly summarize Peter's work before I dive into how this relates to my ongoing project on [disciplined inconsistency](disciplined-inconsistency.html). The paper also does a good job of summarizing a bunch of other work that's been done bounding staleness or inconsistency in various ways (which saves me a bunch of time, thanks!).

## When is eventually?

> In order to be web-scale, apps need low-latency access to their Big Data; they can't afford the luxuries of relational schemas or consistency. Anyway, I totally use Cassandra and I like never see anything go wrong as long as I refresh once or twice.[^brogrammer]

Okay, sorry, brogrammer-ness aside, this is actually not far off. We know there are some fundamental limits to providing high availability with strong consistency [^cap], which is why in some cases we need to sacrifice consistency for lower latency by replicating data. But we also have a bunch of anecdotal evidence that things tend to turn out alright when we run things like Twitter or LinkedIn or even Amazon on replicated datastores. Gee, wouldn't it be nice if someone actually measured this, and could give you some guarantees on how inconsistent your system will be?

> [...] we quantify the degree to which eventual consistency is both eventual and consistent [...]

In addition to being a great line in the paper, it's also exactly what we want. In their work, Peter Bailis et al. defined *Probabilistic Bounded Staleness* to quantify the different ways that data can be inconsistent.

It turns out that given typical replication settings and network/write latency distributions (generously provided by LinkedIn and Yammer), 

[^brogrammer]: Not a real quote. But I think we've all heard something along these lines before.
[^cap]: Something something CAP Theorem... (but there's more to it)
